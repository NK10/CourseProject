{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "938590c6f5ea4160832e21c8dadb8670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50ea06324a524d488f14d0bf641a5180",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae9ad4cbec724863b9626f4ded143bc9",
              "IPY_MODEL_d127e9aeda264e9788c83345a7b6ff3c"
            ]
          }
        },
        "50ea06324a524d488f14d0bf641a5180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae9ad4cbec724863b9626f4ded143bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b54ee8e7f0ca47cfbb4f988d596bba50",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee4f5654eca243f7ad22938f03f4bc1d"
          }
        },
        "d127e9aeda264e9788c83345a7b6ff3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04a360ecbd8443abbabb983ba69f97db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.70MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8af6b5eaed6f49a4b5f515776d1381b3"
          }
        },
        "b54ee8e7f0ca47cfbb4f988d596bba50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee4f5654eca243f7ad22938f03f4bc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04a360ecbd8443abbabb983ba69f97db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8af6b5eaed6f49a4b5f515776d1381b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9059dbeb641248e089acc6f66d74aaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12b2e836c2ca43f38af0339ca5a74e2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bfb27da583240e8a2d51ce6b5a28724",
              "IPY_MODEL_2236c3ac0a5c4b9eadd93835948dc7ea"
            ]
          }
        },
        "12b2e836c2ca43f38af0339ca5a74e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bfb27da583240e8a2d51ce6b5a28724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3262ff8150774e88b8bab717097199f1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ff2805fe4b748f286968fd4e9a1d97d"
          }
        },
        "2236c3ac0a5c4b9eadd93835948dc7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea6413f25ddc416a9c2c6c20bee536cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.43kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54f58975fabd4a49a61c58fbcb031ab1"
          }
        },
        "3262ff8150774e88b8bab717097199f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ff2805fe4b748f286968fd4e9a1d97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea6413f25ddc416a9c2c6c20bee536cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54f58975fabd4a49a61c58fbcb031ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9aed4fdd8194574b3abd7754a6b88da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15e568ccfa0d4c238f61089cd3485000",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e270b5e6408b4c3fb3daf9f9dcbaccdc",
              "IPY_MODEL_24c12c5a972d465da612c01b263cdeff"
            ]
          }
        },
        "15e568ccfa0d4c238f61089cd3485000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e270b5e6408b4c3fb3daf9f9dcbaccdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69d6dacdbf4a49f18be370aeb102c799",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41fd0265884044e6abadd8466627ab16"
          }
        },
        "24c12c5a972d465da612c01b263cdeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebc9266495e44651a1d69d9c13875a16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 52.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58c755767b924d8ea7574c21bbecd383"
          }
        },
        "69d6dacdbf4a49f18be370aeb102c799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41fd0265884044e6abadd8466627ab16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebc9266495e44651a1d69d9c13875a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58c755767b924d8ea7574c21bbecd383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfpFTfdGGyyK"
      },
      "source": [
        "# About Project \r\n",
        "\r\n",
        "As part of the Course project i am participating in the Text Classification Competition\r\n",
        "\r\n",
        "**Text Classification Competition: Twitter Sarcasm Detection**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og1DptE6Ouol"
      },
      "source": [
        "## About data: \r\n",
        "Here we are given  \r\n",
        "\r\n",
        "*   **label** : (SARCASAM and NOT_SARCASM)\r\n",
        "*   **Context** : Its a list of tweets data for a conversation. Note, the context is an ordered list of dialogue, i.e., if the context contains three elements, c1, c2, c3, in that order, then c2 is a reply to c1 and c3 is a reply to c2. Further, the Tweet to be classified is a reply to c3.\r\n",
        "\r\n",
        "  For instance, for the following training example :\r\n",
        "\r\n",
        "  \"label\": \"SARCASM\", \"response\": \"@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..\", \"context\": [\"A minor child deserves privacy and should be kept out of politics . Pamela Karlan , you should be ashamed of your very angry and obviously biased public pandering , and using a child to do it .\", \"@USER If your child isn't named Barron ... #BeBest Melania couldn't care less . Fact . üíØ\"]\r\n",
        "\r\n",
        "  The response tweet, \"@USER @USER @USER I don't get this...\" is a reply to its immediate context \"@USER If your child isn't...\" which is a reply to \"A minor child deserves privacy...\". Your goal is to predict the label of the \"response\" while optionally using the context (i.e, the immediate or the full context).\r\n",
        "\r\n",
        "\r\n",
        "*   **Response** : Its a response tweet on the last tweet of the context data. This is the tweet to be classified. \r\n",
        "*   **id** : String identifier for sample. This id will be required when making submissions. (ONLY in test data)\r\n",
        "\r\n",
        "\r\n",
        "There are total 5000 records for training and 1800 records for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2HtJIg0O59D"
      },
      "source": [
        "## Importing libraries and loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_91x3QzaGZgw"
      },
      "source": [
        "Importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyHXQ8zpVC1S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "import keras\n",
        "import sklearn\n",
        "import matplotlib as matplot\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX3t6Q9NBJFs"
      },
      "source": [
        "Installing the transformers as this library allows to benefits from large, pretrained language models without requiring a huge and costly computational infrastructure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_EpTPWJU4ep",
        "outputId": "50b74130-c329-48e8-de91-3d2e199a4f61"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.4MB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 54.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.9MB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=04906b4a29f6a3dfcad17413bde0bf9ce2158cd0e36d78a95c34937738758f00\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8VeZxqQkmha",
        "outputId": "ec550044-321d-4df3-e6c3-d3ff38869857"
      },
      "source": [
        "print('Pandas Version', pd.__version__)\r\n",
        "print('Numpy Version', np.__version__)\r\n",
        "print('torch Version', torch.__version__)\r\n",
        "print('transformers Version', 'transformers-4.0.1')\r\n",
        "print('sklearn Version', sklearn.__version__)\r\n",
        "print('matplotlib Version', matplot.__version__)\r\n",
        "print('seaborn Version', sns.__version__)\r\n",
        "%tensorflow_version\r\n",
        "!python --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pandas Version 1.1.5\n",
            "Numpy Version 1.18.5\n",
            "torch Version 1.7.0+cu101\n",
            "transformers Version transformers-4.0.1\n",
            "sklearn Version 0.22.2.post1\n",
            "matplotlib Version 3.2.2\n",
            "seaborn Version 0.11.0\n",
            "Currently selected TF version: 2.x\n",
            "Available versions:\n",
            "* 1.x\n",
            "* 2.x\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smj40AQUD2Da"
      },
      "source": [
        "Here i am checking if we have any available running GPU, if yes then use for the processing otherwise we will use the cpu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0KlHJN3WVTj",
        "outputId": "02c71d58-c382-4fce-ce7b-080f9e2566e3"
      },
      "source": [
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq0B5Lb8FgV_"
      },
      "source": [
        "Setting the maximum column width for columns. Cells of this length or longer will be truncated with an ellipsis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axTnRWixKhW3"
      },
      "source": [
        "pd.set_option('display.max_colwidth', 1000)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urLrhvTEGUHh"
      },
      "source": [
        "Reading the train and test data\r\n",
        "\r\n",
        "**Please ensure to specify the location of the files of train and test data so that the read_json can access and readt it**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGD-MdV2ViZN"
      },
      "source": [
        "train_data = pd.read_json('train.jsonl',lines=True)\n",
        "test_data = pd.read_json('test.jsonl',lines=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h63rCf5tGX9B"
      },
      "source": [
        "See the first few records of Train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "XQgHe3aNKVIB",
        "outputId": "2f4c2785-b947-4cd1-cfea-2060430e1d67"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER I don't get this .. obviously you do care or you would've moved right along .. instead you decided to care and troll her ..</td>\n",
              "      <td>[A minor child deserves privacy and should be kept out of politics . Pamela Karlan , you should be ashamed of your very angry and obviously biased public pandering , and using a child to do it ., @USER If your child isn't named Barron ... #BeBest Melania couldn't care less . Fact . üíØ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make em ?</td>\n",
              "      <td>[@USER @USER Why is he a loser ? He's just a Press Secretary, @USER @USER having to make up excuses of why your crowd was small .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER @USER He makes an insane about of money from the MOVIES , Einstein ! #LearnHowTheSystemWorks</td>\n",
              "      <td>[Donald J . Trump is guilty as charged . The evidence is clear . If your Senator votes to acquit , remember him / her at the ballot box ., @USER I ‚Äô ll remember to not support you at the box office .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Meanwhile Trump won't even release his SAT scores and his Wharton professors said he was the dumbest student they've ever taught</td>\n",
              "      <td>[Jamie Raskin tanked Doug Collins . Collins looks stupid . &lt;URL&gt;, @USER But not half as stupid as Schiff looks . People's looks are what nature creates . Abilities of people are what they create for themselves . Just for looks , Lincoln was not tops but with his education and understanding made him great .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd Claimed That \" Democracy Was on the Ballot \" in 1860 , too . They Thought Lincoln Was \" Authoritarian \" . #GOP #PartyOfLincoln #Democrats</td>\n",
              "      <td>[Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apocalypse one day . &lt;URL&gt;, @USER They already did . Obama said many times during the 2016 campaign that democracy was on the ballot . Then . Hillary warned you , so did every single expert in authoritarianism . The media , like millions of Americans , refused to believe them .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label  ...                                                                                                                                                                                                                                                                                                                           context\n",
              "0  SARCASM  ...                                     [A minor child deserves privacy and should be kept out of politics . Pamela Karlan , you should be ashamed of your very angry and obviously biased public pandering , and using a child to do it ., @USER If your child isn't named Barron ... #BeBest Melania couldn't care less . Fact . üíØ]\n",
              "1  SARCASM  ...                                                                                                                                                                                                [@USER @USER Why is he a loser ? He's just a Press Secretary, @USER @USER having to make up excuses of why your crowd was small .]\n",
              "2  SARCASM  ...                                                                                                                          [Donald J . Trump is guilty as charged . The evidence is clear . If your Senator votes to acquit , remember him / her at the ballot box ., @USER I ‚Äô ll remember to not support you at the box office .]\n",
              "3  SARCASM  ...              [Jamie Raskin tanked Doug Collins . Collins looks stupid . <URL>, @USER But not half as stupid as Schiff looks . People's looks are what nature creates . Abilities of people are what they create for themselves . Just for looks , Lincoln was not tops but with his education and understanding made him great .]\n",
              "4  SARCASM  ...  [Man ... y ‚Äô all gone ‚Äú both sides ‚Äù the apocalypse one day . <URL>, @USER They already did . Obama said many times during the 2016 campaign that democracy was on the ballot . Then . Hillary warned you , so did every single expert in authoritarianism . The media , like millions of Americans , refused to believe them .]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "pSgZHN8OUNly",
        "outputId": "8ca19bc5-8328-4c9b-975c-0065dd0a7cd6"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_1</td>\n",
              "      <td>@USER @USER @USER My 3 year old , that just finished reading Nietzsche and then asked me : \" ayo papa why these people always trying to cancel someone on Twitter , trying to pretend like that makes them better themselves ? \" . To which I replied \" idk \" , and he just \" cuz hoes mad \" . Im so proud . &lt;URL&gt;</td>\n",
              "      <td>[Well now that ‚Äô s problematic AF &lt;URL&gt;, @USER @USER My 5 year old ... asked me why they are making fun of Native Americans .., @USER @USER @USER I will take shit that didn't happen for $ 100, @USER @USER @USER No .. he actually in the gifted program and reads on second grade level .  ... and he knows Kansas City is in Missouri]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twitter_2</td>\n",
              "      <td>@USER @USER How many verifiable lies has he told now ? 15,000+ documented . He's a truth teller for sure .</td>\n",
              "      <td>[Last week the Fake News said that a section of our powerful , under construction , Southern Border Wall ‚Äú fell over ‚Äù , trying to make it sound terrible , except the reason was that the concrete foundation was just poured &amp; soaking wet when big winds kicked in . Quickly fixed ‚Äú forever ‚Äù ., @USER The mainstream media doesn't report the facts ; yet , the truth is available from the current resident of 1600 Pennsylvania Avenue , Washington D . C . ~]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>twitter_3</td>\n",
              "      <td>@USER @USER @USER Maybe Docs just a scrub of a coach ... I mean to get hammered with that gold standard team</td>\n",
              "      <td>[@USER Let ‚Äô s Aplaud Brett When he deserves it he coached an amazing game &lt;URL&gt;, @USER @USER He did try keep korkmaz in in the 4th quarter when he was a defensive liability . And Sixers had a shit clock violation AFTER a timeout . And kept horford w embiid while clippers went small ball . And Scott over Robinson was not very smart . But for bretts standards ... &lt;URL&gt;]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>twitter_4</td>\n",
              "      <td>@USER @USER is just a cover up for the real hate inside @USER . The left in a nutshell ! &lt;URL&gt;</td>\n",
              "      <td>[Women generally hate this president . What's up with men ?, @USER I've hated him before he was placed in office , now I hate all his enablers as much as him , you woman will save this country and our world . Some of us men know that , are ok with that , admire that and will help with that .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twitter_5</td>\n",
              "      <td>@USER @USER @USER The irony being that he even has to ask why .</td>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing clips of ordinary Brexit voters struggling to articulate themselves as well as they might on live TV proves nothing about them or the Brexit vote . It just proves you lot are petty , snobbish c * * * s ., @USER When Spiked claim that Brexiteers knew exactly what they were voting for , it's quite obviously untrue in many cases . It's not snobbery - but let's be honest about the fact that , on both sides of t debate , there was a lot of ignorance . #thick, @USER @USER Quite an articulate and considered comment but then finishes with ' that ' hashtag proving that he's still a #twat]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context\n",
              "0  twitter_1  ...                                                                                                                                                                                                                                                                                                                [Well now that ‚Äô s problematic AF <URL>, @USER @USER My 5 year old ... asked me why they are making fun of Native Americans .., @USER @USER @USER I will take shit that didn't happen for $ 100, @USER @USER @USER No .. he actually in the gifted program and reads on second grade level .  ... and he knows Kansas City is in Missouri]\n",
              "1  twitter_2  ...                                                                                                                                                                                     [Last week the Fake News said that a section of our powerful , under construction , Southern Border Wall ‚Äú fell over ‚Äù , trying to make it sound terrible , except the reason was that the concrete foundation was just poured & soaking wet when big winds kicked in . Quickly fixed ‚Äú forever ‚Äù ., @USER The mainstream media doesn't report the facts ; yet , the truth is available from the current resident of 1600 Pennsylvania Avenue , Washington D . C . ~]\n",
              "2  twitter_3  ...                                                                                                                                                                                                                                                                       [@USER Let ‚Äô s Aplaud Brett When he deserves it he coached an amazing game <URL>, @USER @USER He did try keep korkmaz in in the 4th quarter when he was a defensive liability . And Sixers had a shit clock violation AFTER a timeout . And kept horford w embiid while clippers went small ball . And Scott over Robinson was not very smart . But for bretts standards ... <URL>]\n",
              "3  twitter_4  ...                                                                                                                                                                                                                                                                                                                                                     [Women generally hate this president . What's up with men ?, @USER I've hated him before he was placed in office , now I hate all his enablers as much as him , you woman will save this country and our world . Some of us men know that , are ok with that , admire that and will help with that .]\n",
              "4  twitter_5  ...  [Dear media Remoaners , you excitedly sharing clips of ordinary Brexit voters struggling to articulate themselves as well as they might on live TV proves nothing about them or the Brexit vote . It just proves you lot are petty , snobbish c * * * s ., @USER When Spiked claim that Brexiteers knew exactly what they were voting for , it's quite obviously untrue in many cases . It's not snobbery - but let's be honest about the fact that , on both sides of t debate , there was a lot of ignorance . #thick, @USER @USER Quite an articulate and considered comment but then finishes with ' that ' hashtag proving that he's still a #twat]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eMk9mSZG26m"
      },
      "source": [
        "Creating a new numerical column which will translate if its *SARCASM* then value is 1 otherwise its 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-CqMwkqVtBd"
      },
      "source": [
        "train_data['num_label'] = np.where(train_data['label']=='SARCASM',1,0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqrKbAkfIbc9"
      },
      "source": [
        "## Pre Processing of text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbJkSJb-MK_b"
      },
      "source": [
        "In this step created a function for removing the few words like '@user', '...' and 'url'. Here i am passing *response* column of the row of the dataframe and splitting it into unigram tokens and striping it.\r\n",
        "\r\n",
        "Calling this function on Train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LELWG7AMlruW"
      },
      "source": [
        "custom_list = ['@user','..','<url>']\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in custom_list:\n",
        "            final_text.append(i.strip().lower())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB9eBloalr12"
      },
      "source": [
        "train_data['new_response']=train_data['response'].apply(denoise_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SCNQRPtUmLy"
      },
      "source": [
        "test_data['new_response']=test_data['response'].apply(denoise_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKu6d7b1Vway"
      },
      "source": [
        "sentences = train_data['new_response'].values\n",
        "labels = train_data['num_label'].values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKQu5TnhK20O"
      },
      "source": [
        "test_sentences = test_data['new_response'].values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LdrUyP5WAG1",
        "outputId": "62d1c128-b64a-40cf-d9f5-6e5e765d133e"
      },
      "source": [
        "print('sample showing the processed train data')\r\n",
        "sentences[0], labels[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample showing the processed train data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"i don't get this obviously you do care or you would've moved right along instead you decided to care and troll her\",\n",
              " 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "zhCtY_OTP2xX",
        "outputId": "d8cb29fb-253d-426a-de30-bc541dbfe81f"
      },
      "source": [
        "print('sample showing the processed train data')\r\n",
        "test_sentences[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample showing the processed train data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my 3 year old , that just finished reading nietzsche and then asked me : \" ayo papa why these people always trying to cancel someone on twitter , trying to pretend like that makes them better themselves ? \" . to which i replied \" idk \" , and he just \" cuz hoes mad \" . im so proud .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyKULLuwP_3S"
      },
      "source": [
        "importing BertTokenizer to load the pre-trained model tokenizer (vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "938590c6f5ea4160832e21c8dadb8670",
            "50ea06324a524d488f14d0bf641a5180",
            "ae9ad4cbec724863b9626f4ded143bc9",
            "d127e9aeda264e9788c83345a7b6ff3c",
            "b54ee8e7f0ca47cfbb4f988d596bba50",
            "ee4f5654eca243f7ad22938f03f4bc1d",
            "04a360ecbd8443abbabb983ba69f97db",
            "8af6b5eaed6f49a4b5f515776d1381b3"
          ]
        },
        "id": "Dhu-E2FFWB05",
        "outputId": "6d6b4a47-d789-44e3-ad8b-64c788f1fc69"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "938590c6f5ea4160832e21c8dadb8670",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl1oJpMRSJwf"
      },
      "source": [
        "Showing sample record after the tokenization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5xObrhJWmXz",
        "outputId": "49b0aaea-b73d-4d4e-b6bf-7f7c6564d54e"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  i don't get this obviously you do care or you would've moved right along instead you decided to care and troll her\n",
            "Tokenized:  ['i', 'don', \"'\", 't', 'get', 'this', 'obviously', 'you', 'do', 'care', 'or', 'you', 'would', \"'\", 've', 'moved', 'right', 'along', 'instead', 'you', 'decided', 'to', 'care', 'and', 'troll', 'her']\n",
            "Token IDs:  [1045, 2123, 1005, 1056, 2131, 2023, 5525, 2017, 2079, 2729, 2030, 2017, 2052, 1005, 2310, 2333, 2157, 2247, 2612, 2017, 2787, 2000, 2729, 1998, 18792, 2014]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRGIVBbaSfu6"
      },
      "source": [
        "### encoding\r\n",
        "Created a encoding function to encode every sentence such that it starts with word 'CLS' and end with 'SEP'  and map to their encoding id this is a prerequiste for the model.\r\n",
        "\r\n",
        "Running the function for train and test data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zeXaWHcLBgZ"
      },
      "source": [
        "def encoding (sentences):\r\n",
        "  input_ids = []\r\n",
        "  for sent in sentences:\r\n",
        "      encoded_sent = tokenizer.encode(\r\n",
        "                          sent,                      # Sentence to encode.\r\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\r\n",
        "                    )\r\n",
        "      input_ids.append(encoded_sent)\r\n",
        "  return input_ids"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLJ1jwlrO_uw",
        "outputId": "43462b40-7cf7-430a-cb35-67d8653a3a66"
      },
      "source": [
        "input_ids = encoding (sentences)\r\n",
        "\r\n",
        "print('sample from train set \\n')\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('Original: ', sentences[0])\r\n",
        "print('Token IDs:', input_ids[0])\r\n",
        "\r\n",
        "\r\n",
        "test_input_ids = encoding (test_sentences)\r\n",
        "\r\n",
        "print('\\n sample from test set \\n')\r\n",
        "# Print sentence 0, now as a list of IDs.\r\n",
        "print('\\n Original: ', test_sentences[0])\r\n",
        "print('Token IDs:', test_input_ids[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample from train set \n",
            "\n",
            "Original:  i don't get this obviously you do care or you would've moved right along instead you decided to care and troll her\n",
            "Token IDs: [101, 1045, 2123, 1005, 1056, 2131, 2023, 5525, 2017, 2079, 2729, 2030, 2017, 2052, 1005, 2310, 2333, 2157, 2247, 2612, 2017, 2787, 2000, 2729, 1998, 18792, 2014, 102]\n",
            "\n",
            " sample from test set \n",
            "\n",
            "\n",
            " Original:  my 3 year old , that just finished reading nietzsche and then asked me : \" ayo papa why these people always trying to cancel someone on twitter , trying to pretend like that makes them better themselves ? \" . to which i replied \" idk \" , and he just \" cuz hoes mad \" . im so proud .\n",
            "Token IDs: [101, 2026, 1017, 2095, 2214, 1010, 2008, 2074, 2736, 3752, 28898, 1998, 2059, 2356, 2033, 1024, 1000, 1037, 7677, 13008, 2339, 2122, 2111, 2467, 2667, 2000, 17542, 2619, 2006, 10474, 1010, 2667, 2000, 9811, 2066, 2008, 3084, 2068, 2488, 3209, 1029, 1000, 1012, 2000, 2029, 1045, 3880, 1000, 8909, 2243, 1000, 1010, 1998, 2002, 2074, 1000, 12731, 2480, 7570, 2229, 5506, 1000, 1012, 10047, 2061, 7098, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXP3EeuEW-It",
        "outputId": "bbd456ad-3b38-442e-82d3-51d5f8d46d13"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UloVqqvQfUu9",
        "outputId": "512ecaeb-3b40-4c4e-e3e1-88ec58d96d5d"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in test_input_ids]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCHGVKXyUCGW"
      },
      "source": [
        "### padding data\r\n",
        "\r\n",
        "Padding the train and test data with 0 with the max length per the training data. This is a pre requisite for model to have a fixed length of all the data records.This is one of the hyperparameter and i have tried various values and 88 seems to work best. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnZpZRd8W47Y",
        "outputId": "84859d9a-917a-4045-9aeb-bcb23b03ca26"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "MAX_LEN = 88\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# FOR training data\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# FOR testing data\n",
        "\n",
        "test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 88 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLsehCBMVNu_"
      },
      "source": [
        "### creating attention mask\r\n",
        "\r\n",
        "Creating a attention mask for train and test data which is needed for the model\r\n",
        "*   if a token ID is 0, then it's padding, set the mask to 0.\r\n",
        "*   If a token ID is > 0, then it's a real token, set the mask to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Q0IvNwXBlo"
      },
      "source": [
        "# FOR TRAINING\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhEHc9QkwxDH"
      },
      "source": [
        "# FOR TESTING\n",
        "# Create attention masks\n",
        "test_attention_masks = []\n",
        "\n",
        "for sent in test_input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    test_attention_masks.append(att_mask)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LL13xhmXK00"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "# better results got with 2018\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIkEAKrpWZJB"
      },
      "source": [
        "### Converting data to torch tensor\r\n",
        "\r\n",
        "Convert all inputs and labels into torch tensors, the required datatype for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c1bFY67XNbk"
      },
      "source": [
        "# FOR TRAINING\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av0f9A13x8o7"
      },
      "source": [
        "# FOR TESTING\n",
        "test_input_ids = torch.tensor(test_input_ids)\n",
        "test_attention_masks = torch.tensor(test_attention_masks)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPmmFVzNxrds"
      },
      "source": [
        "### Creating dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ch1aw9BXQFE"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# FOR TRAINING AND VALIDATION\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaQf-uuz0bhF"
      },
      "source": [
        "# FOR TESTING\n",
        "\n",
        "testing_data = TensorDataset(test_input_ids, test_attention_masks)\n",
        "test_sampler = SequentialSampler(testing_data)\n",
        "test_dataloader = DataLoader(testing_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHOioQ2Bx26a"
      },
      "source": [
        "## Loading BertForSequenceClassification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9059dbeb641248e089acc6f66d74aaa2",
            "12b2e836c2ca43f38af0339ca5a74e2a",
            "4bfb27da583240e8a2d51ce6b5a28724",
            "2236c3ac0a5c4b9eadd93835948dc7ea",
            "3262ff8150774e88b8bab717097199f1",
            "5ff2805fe4b748f286968fd4e9a1d97d",
            "ea6413f25ddc416a9c2c6c20bee536cd",
            "54f58975fabd4a49a61c58fbcb031ab1",
            "a9aed4fdd8194574b3abd7754a6b88da",
            "15e568ccfa0d4c238f61089cd3485000",
            "e270b5e6408b4c3fb3daf9f9dcbaccdc",
            "24c12c5a972d465da612c01b263cdeff",
            "69d6dacdbf4a49f18be370aeb102c799",
            "41fd0265884044e6abadd8466627ab16",
            "ebc9266495e44651a1d69d9c13875a16",
            "58c755767b924d8ea7574c21bbecd383"
          ]
        },
        "id": "PNvOrUO-hZlX",
        "outputId": "742e709d-4e01-494d-d92c-9461c531f059"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9059dbeb641248e089acc6f66d74aaa2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9aed4fdd8194574b3abd7754a6b88da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAkqFFdRXSXn"
      },
      "source": [
        "The original Adam algorithm was proposed in [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980). The AdamW variant was proposed in [Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX9MDmg2hgRu"
      },
      "source": [
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaASlkBUXnOu"
      },
      "source": [
        "Tried different epochs as we are increasing the epochs the model was overfitting. 5 seems to work well for me."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE3IC_T4yIKp"
      },
      "source": [
        "## Creating Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtclmgBGhsv9"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhkJ-M0-YEM7"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWTt3Uz1X_vE"
      },
      "source": [
        "Function to calculate the accuracy of our predictions vs labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_NshfI2hv-E"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En64t4iJhz7j"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoP1upCsyLmA"
      },
      "source": [
        "## Training and validation of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImDYMwXPh1vJ",
        "outputId": "5357f467-eb47-4ad8-bdb6-ffc81990eae9"
      },
      "source": [
        "\n",
        "# This training code is based on the `run_glue.py` script here and modified based on the need of this project:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:01:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    141.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    141.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    141.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "daNjCK1CiAB-",
        "outputId": "f3c0cc05-26e3-4c91-dcea-ab4a246878b1"
      },
      "source": [
        "\n",
        "% matplotlib inline\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "matplot.pyplot.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "matplot.pyplot.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "matplot.pyplot.title(\"Training loss\")\n",
        "matplot.pyplot.xlabel(\"Epoch\")\n",
        "matplot.pyplot.ylabel(\"Loss\")\n",
        "\n",
        "matplot.pyplot.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd7PeLT5yWaf"
      },
      "source": [
        "## Prediction on testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iK0AtWV0Fd"
      },
      "source": [
        "Now our model is trained we are going to make prediction on our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8PavBOEkmDm"
      },
      "source": [
        "# FOR TESTING\n",
        "\n",
        "model.eval()\n",
        "test_log =[]\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    #test_logits = logits.detach().cpu().numpy()\n",
        "    test_log.append(logits)        "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm3ahnHryCyf",
        "outputId": "edc88984-bc30-498f-d7cc-1b61243bb227"
      },
      "source": [
        "all_logits = torch.cat(test_log, dim=0)\n",
        "probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "print('probabilities of Non_SARCASAM and SARCASAM')\n",
        "probs"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "probabilities of Non_SARCASAM and SARCASAM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36360136, 0.6363987 ],\n",
              "       [0.01824608, 0.9817539 ],\n",
              "       [0.01425592, 0.98574406],\n",
              "       ...,\n",
              "       [0.13947845, 0.8605215 ],\n",
              "       [0.9974612 , 0.00253878],\n",
              "       [0.99606234, 0.00393763]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkJNjHl7RbVR"
      },
      "source": [
        "Converting the prediction based on the *threshold value* which we are saying 0.5 for now. I have tried different values as well but 0.5 was giving better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpIqpBmf1caj"
      },
      "source": [
        "threshold = 0.5\n",
        "final_pred = np.where(probs[:, 1] >= threshold, 'SARCASM', 'NOT_SARCASM')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOJgc-jEyc3b"
      },
      "source": [
        "## Generating output file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJVhcc7NQ_pj"
      },
      "source": [
        "Concatinating the out for the test data. We are taking the id and adding the prediction calculated above and writing it on a '*answer.txt*' file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6A8oNTL1LGH"
      },
      "source": [
        "results = pd.DataFrame(test_data['id'])\n",
        "results['label']=final_pred\n",
        "results.to_csv('answer.txt',index=False, header=False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNaMGKqTSTx0"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Krp1QujYc9N"
      },
      "source": [
        "*   https://www.youtube.com/watch?v=FKlPCK1uFrc&list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6&index=1\r\n",
        "*   https://mccormickml.com/2019/07/22/BERT-fine-tuning/#5-performance-on-test-set\r\n",
        "*   https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\r\n",
        "*   http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\r\n",
        "*   https://colab.research.google.com/github/huggingface/transformers/blob/master/notebooks/02-transformers.ipynb#scrollTo=TFHTP6CFSXai\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhLK-K9XixJd"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}